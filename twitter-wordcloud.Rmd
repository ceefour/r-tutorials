---
title: "Word Clouds of Indonesian Media Outlet Twitter User Timelines"
author: "Hendy Irawan"
date: "02/04/2015"
output:
  html_document:
    self_contained: no
---

## R Programming Language Tutorial Videos on YouTube

See [R Programming Language Tutorial Videos by Hendy Irawan](https://www.youtube.com/playlist?list=PLKF12aQHzSaN6i1mz2a1Sg2DIKsXHlVmE).

## Installing Packages: libcurl4-openssl-dev, TwitteR, httpuv, tm, wordcloud, RColorBrewer

Install Ubuntu package `libcurl4-openssl-dev` required by `RCurl` R package:

```
sudo aptitude install libcurl4-openssl-dev
```

Install the R packages:

```{r, eval=FALSE}
install.packages(c('TwitteR', 'httpuv', 'tm', 'wordcloud'))
```

## Setup Twitter OAuth

[Get your Twitter app OAuth consumer credentials](https://apps.twitter.com/), then:

```{r, eval=FALSE}
library(twitter)
setup_twitter_oauth(consumer_key, consumer_secret)
```

## Grab data

```{r, eval=FALSE}
tl_hidcom <- userTimeline('hidcom', n=1000, includeRts = TRUE)
```

View it as data frame, make sure to convert to `UTF-8` to avoid encoding issues later:

```{r, eval=FALSE}
tl_hidcom.df <- twListToDF(tl_hidcom)
tl_hidcom.df$text <- iconv(tl_hidcom.df$text, to='utf-8')
View(tl_hidcom.df)
```

Get summary:

```{r}
tl_hidcom.df <- read.csv('tl_hidcom_2015-04-02.csv')
summary(tl_hidcom.df)
```

Save the data frame to CSV:

```{r, eval=FALSE}
write.csv(twListToDF(tl_hidcom), 'tl_hidcom.csv')
```

## Prepare Stop Words

```{r}
stopwords_id = c('ini', 'dengan', 'untuk', 'yang', 'tak', 'tidak', 'gak',
                 'dari', 'dan', 'atau', 'bisa', 'kita', 'ada', 'itu',
                 'akan', 'jadi', 'menjadi', 'tetap', 'per', 'bagi', 'saat',
                 'tapi', 'bukan', 'adalah', 'pula', 'aja', 'saja',
                 'kalo', 'kalau', 'karena',
                 'amp' # &amp;
                 )
```

## Make a Corpus

Grab just text column:

```{r}
head(tl_hidcom.df$text)
```

Make a **tm** `Corpus` from the data frame `VectorSource`:

```{r}
library(tm)
tl_hidcom.corpus <- Corpus(VectorSource(tl_hidcom.df$text))
corpus <- tl_hidcom.corpus
```

Make a `TermDocumentMatrix`, with desired text preprocessors:

```{r}
# Remove Twitter shortened links
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
# Make TermDocumentMatrix
tl_hidcom.tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'hidayatullah', 'hidcom') ))
```

Get the matrix from the `TermDocumentMatrix`:

```{r}
tl_hidcom.m <- as.matrix(tl_hidcom.tdm)
tl_hidcom.m[1:10, 1:20]
# View(tl_hidcom.m)
```

Get the word frequencies for `freq > 0`, and sort them (nice way):

```{r}
tl_hidcom.wf <- sort(rowSums(tl_hidcom.m), decreasing=TRUE)
tl_hidcom.wf <- tl_hidcom.wf[tl_hidcom.wf > 0]
tl_hidcom.dm <- data.frame(word=names(tl_hidcom.wf),
                           freq=tl_hidcom.wf)
head(tl_hidcom.dm)
# View(tl_hidcom.dm)
```

or alternatively: (my own convoluted way hehe ;-) )

```{r}
tl_hidcom.dm <- data.frame(word=rownames(tl_hidcom.m),
                           freq=rowSums(tl_hidcom.m))
tl_hidcom.dm <- tl_hidcom.dm[tl_hidcom.dm$freq > 0,]
tl_hidcom.dm <- tl_hidcom.dm[order(tl_hidcom.dm$freq, decreasing=TRUE),]
head(tl_hidcom.dm)
# View(tl_hidcom_dm)
```

## Word Cloud

Just to be sane, only the first 300 words:

```{r}
library(wordcloud)
wordcloud(head(tl_hidcom.dm$word, 300), head(tl_hidcom.dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

## Other Medias

### @dakwatuna

```{r}
library(twitteR)
library(tm)
library(wordcloud)

# tl_dakwatuna <- userTimeline('dakwatuna', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_dakwatuna), '~/git/r-tutorials/tl_dakwatuna_2015-04-03.csv')
df <- read.csv('tl_dakwatuna_2015-04-03.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'dakwatuna') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @suaradotcom

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_suaradotcom <- userTimeline('suaradotcom', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_suaradotcom), '~/git/r-tutorials/tl_suaradotcom_2015-04-02.csv')
df <- read.csv('tl_suaradotcom_2015-04-02.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'suaradotcom') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @kompascom

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_kompascom <- userTimeline('kompascom', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_kompascom), '~/git/r-tutorials/tl_kompascom_2015-04-02.csv')
df <- read.csv('tl_kompascom_2015-04-02.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'kompascom', 'kompas') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @VIVAnews

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_vivanews <- userTimeline('VIVAnews', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_vivanews), '~/git/r-tutorials/tl_vivanews_2015-04-02.csv')
df <- read.csv('tl_vivanews_2015-04-02.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'viva', 'vivanews', 'vivacoid', 'vivalife', 'vivabola', 'vivalog') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @liputan6dotcom

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_liputan6dotcom <- userTimeline('liputan6dotcom', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_liputan6dotcom), '~/git/r-tutorials/tl_liputan6dotcom_2015-04-02.csv')
df <- read.csv('tl_liputan6dotcom_2015-04-02.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'liputan6dotcom', 'liputan6') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @pkspiyungan

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_pkspiyungan <- userTimeline('pkspiyungan', n=1000, includeRts = TRUE)
# write.csv(twListToDF(tl_pkspiyungan), '~/git/r-tutorials/tl_pkspiyungan_2015-04-02.csv')
df <- read.csv('tl_pkspiyungan_2015-04-02.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'pkspiyungan') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @MTlovenhoney

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_mtlovenhoney <- userTimeline('MTlovenhoney', n=1000, includeRts = TRUE)
# df <- twListToDF(tl_mtlovenhoney)
# df$text <- iconv(df$text, to='UTF-8')
# write.csv(df, '~/git/r-tutorials/tl_mtlovenhoney_2015-04-03.csv')
df <- read.csv('tl_mtlovenhoney_2015-04-03.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'mtlovenhoney', 'mario', 'teguh', 'marioteguh', 'mtgw') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```

### @farhatabbaslaw

```{r, warning=FALSE}
library(twitteR)
library(tm)
library(wordcloud)

# tl_farhatabbaslaw <- userTimeline('farhatabbaslaw', n=1000, includeRts = TRUE)
# df <- twListToDF(tl_farhatabbaslaw)
# df$text <- iconv(df$text, to='UTF-8')
# write.csv(df, '~/git/r-tutorials/tl_farhatabbaslaw_2015-04-03.csv')
df <- read.csv('tl_farhatabbaslaw_2015-04-03.csv')
corpus <- Corpus(VectorSource(df$text))
corpus <- tm_map(corpus, content_transformer(function(x) gsub('http\\S+t.co\\S+', '', x)))
tdm <- TermDocumentMatrix(corpus,
  control = list(stripWhitespace = TRUE, tolower = TRUE,
                 removeNumbers = TRUE,
                 removePunctuation = TRUE,
                 stopwords = c(stopwords_id, 'farhatabbaslaw', 'farhatabbas', 'farhat', 'abbas') ))
m <- as.matrix(tdm)
wf <- sort(rowSums(m), decreasing=TRUE)
wf <- wf[wf > 0]
dm <- data.frame(word=names(wf), freq=wf)
wordcloud(head(dm$word, 300), head(dm$freq, 300),
          random.order=FALSE, colors=brewer.pal(8, 'Dark2'))
```
